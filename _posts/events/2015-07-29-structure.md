---
layout: event
title:  "MN VR and HCI July 2015: Structure Sensor and SDK"
image: "/assets/2015/2015-07-29.jpg"
categories: events vr-hci
eventbrite: "https://www.eventbrite.com/e/mn-vr-and-hci-july-2015-structure-sensor-and-sdk-tickets-17800921034?aff=ebdsoporgprofile"
---

#### Structure Sensor and SDK
##### Jim Selikoff, Developer Evangelist for Occipital

Structure shipped in 2014 as the first 3D sensor for mobile hardware, with 3 core capabilities:

- Reliable 3D scanning with high-res textures
- Quick room mapping and measuring
- Multi-modal 6DOF positional tracking (for VR/AR)

Structure was quickly adopted for a variety of 3d scanning applications. As developer experience and the SDK has matured, the capabilities are being combined for interesting use cases like:

- Pre-vis at ILM and on Agents of Shield
- Medical wound care
- Capturing realistic face blenshapes and textures
- Bringing your real environment into a VR or AR scene in real-time

![Structure sensor on an iPad](/assets/2015/2015-07-29-sensor.webp)

The Structure SDK for iOS provides both a low level sensor control layer for raw depth and color streaming, as well as a high level SLAM (Simultaneous Localization and Mapping) layer that includes 3D mapping, tracking and scanning features. For non-iOS platforms, Occipital have taken over the maintenance and evolution of the OSS project OpenNI which enables low level depth streaming on Windows, Android, and Linux platforms.

Come learn how to leverage this incredible technology as we demonstrate and discuss the sensor capabilities along with the design and use of the SDK.

